{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r\"C:\\Users\\gonca\\Documents\\GitHub\\Portefolio_SI\\src\")\n",
    "\n",
    "from iobla.csv_file import read_csv\n",
    "from data.dataset import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1\n",
    "dataset = read_csv(r\"..\\datasets\\iris\\iris.csv\", sep = \",\", features = \"True\", label = True)\n",
    "dataset2 = read_csv(r\"..\\datasets\\iris\\iris_missing_data.csv\", sep = \",\", features = \"True\", label = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.2\n",
    "len(dataset.X[:, -2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.45, 3.03, 5.33, 2.17])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.3\n",
    "temp = dataset.X[-10: , : ]\n",
    "Dataset(temp).get_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n"
     ]
    }
   ],
   "source": [
    "#1.4\n",
    "l = []\n",
    "for x in range(0, len(dataset.X)):\n",
    "    for y in dataset.X[x, :]:\n",
    "        if y <= 6:\n",
    "            l.append(x)\n",
    "counts = {}\n",
    "for number in l:\n",
    "    if number in counts:\n",
    "        counts[number] += 1\n",
    "    else:\n",
    "        counts[number] = 1\n",
    "\n",
    "final = []\n",
    "for x in counts:\n",
    "    if counts[x] == 4:\n",
    "        final.append(x)\n",
    "print(len(final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.4 alternativa\n",
    "import numpy as np\n",
    "temp = dataset.X <= 6  \n",
    "final = dataset.X[np.all(temp, axis=1)] \n",
    "final.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "#1.5 \n",
    "counter = 0\n",
    "for x in dataset.y:\n",
    "    if x != \"Iris-setosa\":\n",
    "        counter += 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.5 alternativa\n",
    "dataset.X[dataset.y != 'Iris-setosa'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.1 dataset sem NaN\n",
    "lines = np.isnan(dataset.X).any(axis=1)\n",
    "dataset.X = dataset.X[~lines]\n",
    "if dataset.has_label():\n",
    "            dataset.y = dataset.y[~lines]\n",
    "dataset.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.1 dataset com Nan\n",
    "lines = np.isnan(dataset2.X).any(axis=1)\n",
    "dataset2.X = dataset2.X[~lines]\n",
    "if dataset2.has_label():\n",
    "            dataset2.y = dataset2.y[~lines]\n",
    "dataset2.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_selection.select_k_best import SelectKBest\n",
    "from feature_selection.variance_threshold import VarianceThreshold\n",
    "from feature_selection.select_percentile import SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector = SelectKBest()\n",
    "selector = selector.fit(dataset)\n",
    "dataset = selector.transform(dataset)\n",
    "new = selector.fit_transform(dataset)\n",
    "\n",
    "new.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector = VarianceThreshold()\n",
    "selector = selector.fit(dataset)\n",
    "dataset = selector.transform(dataset)\n",
    "new = selector.fit_transform(dataset)\n",
    "\n",
    "new.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector = SelectPercentile(percentile=60)\n",
    "selector = selector.fit(dataset)\n",
    "dataset = selector.transform(dataset)\n",
    "new = selector.fit_transform(dataset)\n",
    "\n",
    "new.shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.\n",
    "# in the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2\n",
    "from decomposition.pca import PCA\n",
    "from sklearn.decomposition import PCA as pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "a = pca.fit_transform(dataset.X)\n",
    "\n",
    "pcask = pca(n_components=2)\n",
    "b = pcask.fit_transform(dataset.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from neural_networks.layers import *\n",
    "from neural_networks.optimizers import *\n",
    "from neural_networks.losses import *\n",
    "from metrics import accuracy\n",
    "from neural_networks.neural_network import NeuralNetwork\n",
    "from neural_networks.activation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ReLUActivation' object has no attribute 'initialize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gonca\\Documents\\GitHub\\Portefolio_SI\\src\\Exercises.ipynb Cell 30\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gonca/Documents/GitHub/Portefolio_SI/src/Exercises.ipynb#X42sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model \u001b[39m=\u001b[39m NeuralNetwork(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gonca/Documents/GitHub/Portefolio_SI/src/Exercises.ipynb#X42sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     epochs\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gonca/Documents/GitHub/Portefolio_SI/src/Exercises.ipynb#X42sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     batch_size\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gonca/Documents/GitHub/Portefolio_SI/src/Exercises.ipynb#X42sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     metric\u001b[39m=\u001b[39maccuracy\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gonca/Documents/GitHub/Portefolio_SI/src/Exercises.ipynb#X42sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gonca/Documents/GitHub/Portefolio_SI/src/Exercises.ipynb#X42sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m model\u001b[39m.\u001b[39madd(DenseLayer(n_units\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m, input_shape\u001b[39m=\u001b[39m(\u001b[39m32\u001b[39m,)))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/gonca/Documents/GitHub/Portefolio_SI/src/Exercises.ipynb#X42sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m model\u001b[39m.\u001b[39madd(ReLUActivation())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gonca/Documents/GitHub/Portefolio_SI/src/Exercises.ipynb#X42sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m model\u001b[39m.\u001b[39madd(DenseLayer(n_units\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gonca/Documents/GitHub/Portefolio_SI/src/Exercises.ipynb#X42sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m model\u001b[39m.\u001b[39madd(ReLUActivation())\n",
      "File \u001b[1;32mc:\\Users\\gonca\\Documents\\GitHub\\Portefolio_SI\\src\\neural_networks\\neural_network.py:52\u001b[0m, in \u001b[0;36mNeuralNetwork.add\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m     49\u001b[0m     layer\u001b[39m.\u001b[39mset_input_shape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39moutput_shape())\n\u001b[0;32m     51\u001b[0m \u001b[39m# Initialize the layer with the optimizer\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m layer\u001b[39m.\u001b[39minitialize(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer)\n\u001b[0;32m     54\u001b[0m \u001b[39m# Append the layer to self.layers\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mappend(layer)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ReLUActivation' object has no attribute 'initialize'"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "X_train = np.random.randn(1000, 32)\n",
    "y_train = n \n",
    "X_test = np.random.randn(200, 32)\n",
    "y_test = np.random.randint(0, 2, size=(200, 1))\n",
    "\n",
    "model = NeuralNetwork(\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    optimizer=SGD,\n",
    "    learning_rate=0.01,\n",
    "    verbose=True,\n",
    "    loss=BinaryCrossEntropy,\n",
    "    metric=accuracy\n",
    ")\n",
    "\n",
    "model.add(DenseLayer(n_units=16, input_shape=(32,)))\n",
    "model.add(ReLUActivation())\n",
    "model.add(DenseLayer(n_units=8))\n",
    "model.add(ReLUActivation())\n",
    "model.add(DenseLayer(n_units=1))\n",
    "model.add(SigmoidActivation())\n",
    "\n",
    "model.fit((X_train, y_train))\n",
    "\n",
    "test_accuracy = model.score((X_test, y_test))\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
